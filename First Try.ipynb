{"cells":[{"metadata":{"_uuid":"d8d11b22-d1d8-4c24-845f-efa9ea75a54e","_cell_guid":"e7527db4-0d7b-45d0-9e0c-32c8a2590ffd","trusted":true},"cell_type":"markdown","source":"# Overview"},{"metadata":{"_uuid":"1c713878-b941-415f-9fa4-ca4752d33b65","_cell_guid":"fe7c726b-4de5-4278-b734-3bb083206469","trusted":true},"cell_type":"code","source":"#import \nimport pandas as pd, numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import *\nimport tokenizers\nimport os\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport re\nimport string\nprint('TF version',tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77872c16-1e92-44a2-bff9-7e405e7fda4d","_cell_guid":"59190bc3-0b5f-4212-9d92-f648348e64c4","trusted":true},"cell_type":"code","source":"os.listdir('../input/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"309a9375-bae5-4b61-af79-9fb1b9b1e1ef","_cell_guid":"c734fc89-1b6b-4fb9-9633-9f82e416ee74","trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d09290aa-dfd1-4572-ab21-33aebbbb7626","_cell_guid":"36a90a3e-75aa-47af-abf4-01bcfc6ba039","trusted":true},"cell_type":"markdown","source":"## Reading Datasets"},{"metadata":{"_uuid":"e338c689-7910-44f5-a589-d7bc4f993ce4","_cell_guid":"aaa96171-8466-4dad-8327-faedbf77e00c","trusted":true},"cell_type":"code","source":"#Training data\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\nsample = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)\nprint('Testing sample shape: ', sample.shape)\n\n# First few rows of the training dataset\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1282caf1-aae2-42d1-88c9-128b9c3c1a75","_cell_guid":"72bf53ee-50fc-4147-a6b4-5ce0ecb3bb6a","trusted":true},"cell_type":"code","source":"# First few rows of the testing dataset\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b10269e2-64d2-484a-a8df-eefe6a7a5dd1","_cell_guid":"064c1721-a70a-40b5-970b-4f9073dea55d","trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03e15aa8-c382-4b37-999e-75547e0ddc83","_cell_guid":"55007021-1b19-484f-8472-af4825b05b60","trusted":true},"cell_type":"markdown","source":"## Data exploration"},{"metadata":{"_uuid":"8add6ad4-4d3b-4dfc-803b-fcf10690fea6","_cell_guid":"b6e86572-9ad2-4061-a31d-8ea30575fb2b","trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60392c71-3173-4552-b7e4-2697fc987b77","_cell_guid":"de1f28a4-0968-4611-b1c8-33f4c7d21b0f","trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d2c91e5-84f5-4c01-86c7-a0ad94fb6961","_cell_guid":"3609d774-bc61-45d8-91d7-81c9167abcc2","trusted":true},"cell_type":"code","source":"### Check for null values\ntest.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3740999e-7eae-440c-bf01-91dea1e0f719","_cell_guid":"76e1840b-d20f-4873-af91-846f5166a099","trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fb2ab05-c7e7-41ab-a979-dc36594b62bf","_cell_guid":"7b6f441b-8f1a-4e2d-8552-4b718b565abc","trusted":true},"cell_type":"code","source":"### Drop textID column and any null rows\ntrain.drop(['textID'],axis=1,inplace = True)\ntrain.dropna(axis=0,how='any',inplace = True)\ntest.drop(['textID'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f1a5951-0b6a-4e67-af20-583a446f94d6","_cell_guid":"f361437b-3a7a-4657-a370-c412de15cb57","trusted":true},"cell_type":"markdown","source":"## Visualisation"},{"metadata":{"_uuid":"ada4a9bc-c8b2-4a4f-93f4-0940b177fc1a","_cell_guid":"32cc3ed3-8b8a-4b35-8a2a-ebbbd22fb2dc","trusted":true},"cell_type":"code","source":"### Distribution of sentiment \nsn.set(style=\"darkgrid\")\nsn.countplot(x=train[\"sentiment\"])\nplt.title(\"Training_set\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7aaade7a-b9ae-4159-a83b-5a9b163588d6","_cell_guid":"a5067b0d-380b-4ac7-8810-bc431b7dd0a5","trusted":true},"cell_type":"code","source":"sn.set(style=\"darkgrid\")\nsn.countplot(x=test[\"sentiment\"])\nplt.title(\"Test_set\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7102119-a563-4682-aa3b-13aa1088cf59","_cell_guid":"93cd9929-648c-46b8-8dc9-f05c1b4b9ac9","trusted":true},"cell_type":"code","source":"### Text length\npositive=train[train[\"sentiment\"]==\"positive\"]\nneutral=train[train[\"sentiment\"]==\"neutral\"]\nnegative=train[train[\"sentiment\"]==\"negative\"]\n\n\nsn.distplot(positive[\"text\"].str.split().str.len(),axlabel=\"length of text in having postive sentiment\")\nplt.show()\nsn.distplot(negative[\"text\"].str.split().str.len(),axlabel=\"length of text in having negative sentiment\")\nplt.show()\nsn.distplot(neutral[\"text\"].str.split().str.len(),axlabel=\"length of text in having neutral sentiment\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d36d7d21-76d9-4896-af5a-9535b7007c55","_cell_guid":"663746f6-58db-4d22-9031-b3060deacb96","trusted":true},"cell_type":"markdown","source":"## Clean text"},{"metadata":{"_uuid":"9a230025-e7ae-499c-8680-1223abd575ca","_cell_guid":"83d7b102-5edc-4ad0-bfed-758388590143","trusted":true},"cell_type":"code","source":"def cleaning(txt):\n    txt = txt.lower()\n    txt = re.sub('https?://\\S+|www\\.\\S+', '', txt)\n    txt = re.sub(\"\\n\",\" \", txt)\n    txt = re.sub('\\w*\\d\\w*', '', txt)\n    txt = re.sub('<.*?>+', '', txt)\n    # txt = re.sub('[%s]' % re.escape(string.punctuation), '', txt)\n    return txt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81620f97-c3ba-4e68-b55c-b9db8873639b","_cell_guid":"54949596-5cd3-4eaa-ae3d-525e688e29c5","trusted":true},"cell_type":"code","source":"train['text'] = train['text'].apply(str).apply(lambda x:cleaning(x))\ntest['text'] = test['text'].apply(str).apply(lambda x:cleaning(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c05f880d-d5d6-48c9-bedb-1b580ff459cb","_cell_guid":"bc98306e-2d37-408d-a633-7d1f344179c0","trusted":true},"cell_type":"code","source":"### Clean selected text \ntrain['selected_text'] = train['selected_text'].apply(str).apply(lambda x:cleaning(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"614de1dc-32d7-4249-87ea-4e896eca261c","_cell_guid":"6bc0513b-60ce-4953-92aa-29e28d67f5b2","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b21e31b1-723c-4671-99c7-50598906903c","_cell_guid":"14940aec-ee71-4df8-8fcd-3ec19657398e","trusted":true},"cell_type":"markdown","source":"# Tokenizer"},{"metadata":{"_uuid":"1f797a4c-3ebc-4ccb-a04a-1844707b245e","_cell_guid":"5fb76ebd-9c90-475f-9de0-39b0a56251bf","trusted":true},"cell_type":"code","source":"MAX_LEN = 96\nPATH = '../input/tf-roberta/'\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab_file=PATH+'vocab-roberta-base.json', \n    merges_file=PATH+'merges-roberta-base.txt', \n    lowercase=True,\n    add_prefix_space=True\n)\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b230bf8c-a8e2-4b8a-8914-a0af0405fd06","_cell_guid":"4f2202e7-e17f-431b-a2dc-42a4595f81c2","trusted":true},"cell_type":"code","source":"### Tensor Inputs\n\nct = train.shape[0]\ninput_ids = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\nstart_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\nend_tokens = np.zeros((ct,MAX_LEN),dtype='int32')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e5dc42a-396d-4301-ba35-adfef38f8d1e","_cell_guid":"2985d130-1ff2-47b1-8e2d-8e570af832cb","trusted":true},"cell_type":"markdown","source":"## Encoding"},{"metadata":{"_uuid":"2527e114-1546-489d-836e-e6b8e073b67c","_cell_guid":"80ad663e-09b2-439d-b896-dbf8ad879120","trusted":true},"cell_type":"code","source":"### ENCODING ###\n\n### For training\n\nfor k in range(train.shape[0]):\n    \n    # FIND OVERLAP\n    text1 = \" \"+\" \".join(train.iloc[k,0].split())\n    text2 = \" \".join(train.iloc[k,1].split())\n    idx = text1.find(text2)\n    chars = np.zeros((len(text1)))\n    chars[idx:idx+len(text2)]=1\n    if text1[idx-1]==' ': chars[idx-1] = 1 \n    enc = tokenizer.encode(text1) \n        \n    # ID_OFFSETS\n    offsets = []; idx=0\n    for t in enc.ids:\n        w = tokenizer.decode([t])\n        offsets.append((idx,idx+len(w)))\n        idx += len(w)\n    \n    # START END TOKENS\n    toks = []\n    for i,(a,b) in enumerate(offsets):\n        sm = np.sum(chars[a:b])\n        if sm>0: toks.append(i) \n        \n    s_tok = sentiment_id[train.iloc[k,2]]\n    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask[k,:len(enc.ids)+5] = 1\n    if len(toks)>0:\n        start_tokens[k,toks[0]+1] = 1\n        end_tokens[k,toks[-1]+1] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38242b5a-9ab6-43ff-9453-0e7a39cd60c0","_cell_guid":"78023e01-6a69-4c85-a249-2f5a373b7df8","trusted":true},"cell_type":"code","source":"### For Testing\n\nct = test.shape[0]\ninput_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(test.shape[0]):\n        \n    # INPUT_IDS\n    text1 = \" \"+\" \".join(test.iloc[k,0].split())\n    enc = tokenizer.encode(text1)                \n    s_tok = sentiment_id[test.iloc[k,1]]\n    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask_t[k,:len(enc.ids)+5] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65293418-bb20-4445-b2b2-b630af41e3fb","_cell_guid":"9746117d-06ec-42f6-94ad-d91dd70f577c","trusted":true},"cell_type":"markdown","source":"## Build Model"},{"metadata":{"_uuid":"70418a8a-22ec-4b26-83dd-b9ef1ab63d8c","_cell_guid":"1561a91b-0c6a-4187-bade-8868d9e2ff01","trusted":true},"cell_type":"code","source":"### Model Building\n\ndef build_model():\n    #Inputs\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    \n    #Pretrained roBERTa Config\n    config = RobertaConfig.from_pretrained(PATH + 'config-roberta-base.json')\n    #Model \n    bert_model = TFRobertaModel.from_pretrained(PATH + 'pretrained-roberta-base.h5', config=config)\n    x = bert_model(ids, attention_mask=att, token_type_ids=tok)\n    \n    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x1 = tf.keras.layers.Conv1D(128, 2,padding='same')(x1)\n    x1 = tf.keras.layers.LeakyReLU()(x1)\n    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n    x1 = tf.keras.layers.Dense(1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n    \n    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x2 = tf.keras.layers.Conv1D(128, 2, padding='same')(x2)\n    x2 = tf.keras.layers.LeakyReLU()(x2)\n    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n    x2 = tf.keras.layers.Dense(1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n    \n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n    \n    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10307f9c-2595-4776-9803-ae1bf5cb53f4","_cell_guid":"50a101aa-9264-4ce4-9a54-7e8267680982","trusted":true},"cell_type":"markdown","source":"## Run Model"},{"metadata":{"_uuid":"6f1f5915-f7ae-4093-b3ff-96bf56f8103e","_cell_guid":"76ad3f9e-a2b3-4dfc-bb7e-544a56db4aed","trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    if (len(a)==0) & (len(b)==0): return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"429d4425-2c7b-4ea7-a5ac-a4deb9a5f51d","_cell_guid":"dcf8c24e-4cbc-4098-a8f0-3d17579cd27b","trusted":true},"cell_type":"code","source":"%%time\n\n# INitialize start and end token\npreds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\npreds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n\njac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\noof_start = np.zeros((input_ids.shape[0],MAX_LEN))\noof_end = np.zeros((input_ids.shape[0],MAX_LEN))\npreds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\npreds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n\nskf = StratifiedKFold(n_splits=5,shuffle=True,random_state=123)\nfor fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n\n    print('### FOLD %i'%(fold+1))\n    \n    K.clear_session()\n    model = build_model()\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='auto', save_freq='epoch')\n        \n    model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n        epochs=3, batch_size=32, verbose=DISPLAY, callbacks=[sv],\n        validation_data=([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n        [start_tokens[idxV,], end_tokens[idxV,]]))\n    \n    model.load_weights('%s-roberta-%i.h5'%(VER,fold))\n    \n    print('Predicting OOF...')\n    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n    \n    print('Predicting Test...')\n    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n    preds_start += preds[0]/skf.n_splits\n    preds_end += preds[1]/skf.n_splits\n    \n    \n    # DISPLAY FOLD JACCARD\n    all = []\n    for k in idxV:\n        a = np.argmax(oof_start[k,])\n        b = np.argmax(oof_end[k,])\n        if a>b: \n            st = train.iloc[k,0] # IMPROVE CV/LB with better choice here\n        else:\n            text1 = \" \"+\" \".join(train.iloc[k,0].split())\n            enc = tokenizer.encode(text1)\n            st = tokenizer.decode(enc.ids[a-1:b])\n        all.append(jaccard(st,train.iloc[k,1]))\n    jac.append(np.mean(all))\n    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n    print()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73ce8323-12bb-426d-ac2b-d2bfce021e41","_cell_guid":"ee431d56-8e10-4ea2-9e76-d2be3b45d143","trusted":true},"cell_type":"raw","source":"## Import Predicted results"},{"metadata":{"_uuid":"99a3d2bd-8511-4d59-a944-de05b1cc6f44","_cell_guid":"dd8ade79-0f57-4f6d-8678-1908939c92d2","trusted":true},"cell_type":"code","source":"all = []\nfor k in range(input_ids_t.shape[0]):\n    a = np.argmax(preds_start[k,])\n    b = np.argmax(preds_end[k,])\n    if a>b: \n        st = test.iloc[k,0]\n    else:\n        text1 = \" \"+\" \".join(test.iloc[k,0].split())\n        enc = tokenizer.encode(text1)\n        st = tokenizer.decode(enc.ids[a-1:b])\n    all.append(st)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51769b15-9840-43e3-9b06-52ddc9601d15","_cell_guid":"3148f580-4c6e-4023-bd3a-3dfec7250b3a","trusted":true},"cell_type":"code","source":"test1 = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"478a01be-a425-41f1-890d-e8c8cfeb5fe6","_cell_guid":"fa6e7329-0277-49fb-a834-ac491c0ddd4d","trusted":true},"cell_type":"code","source":"test['selected_text'] = all\ntest['textID'] = test1['textID']\ntest.drop(['text'],axis=1,inplace=True)\ntest.drop(['sentiment'],axis=1,inplace=True)\ntest = test[['textID','selected_text']]\ntest[['textID','selected_text']].to_csv('submission.csv',index=False)\npd.set_option('max_colwidth', 60)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ae796df-5f89-4500-be4f-d0c222ebbf88","_cell_guid":"e846b869-6bea-49d4-aa0f-cfbe7d6e6560","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}